# -*- coding: utf-8 -*-
"""Audio_classification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1B0WrnYpc8Qo-P-fz0FAlosZSjsD_74I1
"""

from google.colab import drive
drive.mount('/content/drive')

# !pip install python_speech_features

"""## **Import modules**"""

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import keras
from keras.models import Sequential
from keras.layers import Dense,Conv2D,MaxPool2D,Activation,Flatten,Dropout,LSTM,TimeDistributed
from keras.utils import to_categorical
from keras import backend as k
from sklearn.utils.class_weight import compute_class_weight
import os
import random
import cv2
from tqdm import tqdm
from scipy.io import wavfile
from python_speech_features import mfcc,logfbank
import librosa

"""## **Load the wav files**"""

datadir='/content/drive/My Drive/wavfiles'
instruments=['Acoustic_guitar','Bass_drum','Cello','Clarinet','Double_bass','Flute','Hi_hat','Saxophone','Snare_drum','Violin_or_fiddle']
files=[]

for i in instruments:
  path=os.path.join(datadir,i)
  ins=i
  for music in os.listdir(path):
    files.append([music,ins])

df=pd.DataFrame(files,columns=['fname','label'])
df.set_index('fname',inplace=True)
print(df.head())

for f in df.index:
  ins=df.at[f,'label']
  rate,signal=wavfile.read('/content/drive/My Drive/wavfiles/'+ins+'/'+f)
  df.at[f,'length']=signal.shape[0]/rate
print(df.head())

class_dist=df.groupby(['label'])['length'].mean()
print(class_dist)
df.reset_index(inplace=True)
print(df.head())

plt.pie(class_dist,labels=class_dist.index)
plt.show()

"""## **Plotting**"""

def calc_fft(y,rate):
  n=len(y)
  freq = np.fft.rfftfreq(n,d=1/rate)
  Y = abs(np.fft.rfft(y)/n)
  return (Y,freq)

def plot_signals(y):
  fig,axes=plt.subplots(nrows=2,ncols=5,figsize=(20,7))
  fig.suptitle('Time Series',size=18)
  keys=list(y.keys())
  i=0
  for r in range(2):
    for c in range(5):
      axes[r,c].set_title(keys[i])
      axes[r,c].plot(y[keys[i]])
      i+=1
  plt.show()

def plot_mfcc(mfccs):
  fig, axes=plt.subplots(nrows=2,ncols=5,figsize=(20,4))
  fig.suptitle('MFCC',size=18)
  i=0
  for r in range(2):
    for c in range(5):
      axes[r,c].set_title(list(mfccs.keys())[i])
      axes[r,c].imshow(list(mfccs.values())[i],cmap='hot')
      i+=1
  plt.show()

def plot_fbank(mfccs):
  fig, axes=plt.subplots(nrows=2,ncols=5,figsize=(20,6))
  fig.suptitle('Filter Bank Coefficients',size=18)
  i=0
  for r in range(2):
    for c in range(5):
      axes[r,c].set_title(list(mfccs.keys())[i])
      axes[r,c].imshow(list(mfccs.values())[i],cmap='hot')
      i+=1
  plt.show()

def plot_fft(fft):
  fig, axes=plt.subplots(nrows=2,ncols=5,figsize=(20,7))
  fig.suptitle('Fast Fourier Transform',size=18)
  i=0
  for r in range(2):
    for c in range(5):
      data=list(fft.values())[i]
      Y,freq=data[0],data[1]
      axes[r,c].set_title(list(fft.keys())[i])
      axes[r,c].plot(freq,Y)
      i+=1
  plt.show()

def envelope(y,rate,threshold):
  mask=[]
  y=pd.Series(y).apply(np.abs)
  y_mean=y.rolling(window=int(rate/10),min_periods=1,center=True).mean()
  for m in y_mean:
    if m > threshold:
      mask.append(True)
    else:
      mask.append(False)
  return mask

signals={}
fft={}
fbank={}
mfccs={}

for i in instruments:
  wav_file=df[df['label']==i].iloc[0,0]
  signal,rate=librosa.load('/content/drive/My Drive/wavfiles/'+i+'/'+wav_file,sr=44100)
  mask=envelope(signal,rate,0.0005)
  signal=signal[mask]
  signals[i]=signal

  fft[i]=calc_fft(signal,rate)

  bank=logfbank(signal[:rate],rate,nfilt=26,nfft=1103).T
  fbank[i]=bank
  
  mel=mfcc(signal[:rate],rate,numcep=13,nfilt=26,nfft=1103).T
  mfccs[i]=mel

print(len(signals['Cello']))
print(fft['Cello'][0].shape,fft['Cello'][1].shape)
print(fbank['Cello'].shape)
print(mfccs['Cello'].shape)

plot_signals(signals)

plot_fft(fft)

plot_fbank(fbank)

plot_mfcc(mfccs)

if len(os.listdir('/content/drive/My Drive/Clean_wavfiles'))==0:
  for f in tqdm(df.fname):
    i=df[df['fname']==f]['label'].values[0]
    signal,rate=librosa.load('/content/drive/My Drive/wavfiles/'+i+'/'+f,sr=16000)
    mask=envelope(signal,rate,0.0005)
    signal=signal[mask]
    wavfile.write(filename='/content/drive/My Drive/Clean_wavfiles/'+f,rate=rate,data=signal)

df.set_index('fname',inplace=True)

for f in df.index:
  rate,signal=wavfile.read('/content/drive/My Drive/Clean_wavfiles/'+f)
  df.at[f,'length']=signal.shape[0]/rate

class_dist=df.groupby(['label'])['length'].mean()
print(class_dist)
#df.reset_index(inplace=True)

plt.pie(class_dist,labels=class_dist.index)
plt.show()

n_samples=2*int(df['length'].sum()/0.1)
print(n_samples)

prob_dist=class_dist/class_dist.sum()
print(prob_dist)
choices = np.random.choice(class_dist.index,p=prob_dist)
print(choices)

"""## **Generate audio samples**"""

class Config:
  def __init__(self,mode='conv',nfilt=26,nfeat=13,nfft=512,rate=16000):
    self.mode=mode
    self.nfilt=nfilt
    self.nfeat=nfeat
    self.nfft=nfft
    self.rate=rate
    self.step=int(rate/10)

config=Config(mode='conv')

def build_rand_feat():
  X=[]
  y=[]
  mn,mx = float('inf'),-float('inf')
  for i in tqdm(range(n_samples)):
    rand_class=np.random.choice(class_dist.index,p=prob_dist)
    wav_file=np.random.choice(df[df['label']==rand_class].index)
    rate,signal = wavfile.read('/content/drive/My Drive/Clean_wavfiles/'+wav_file)
    label=df.at[wav_file,'label']
    rand_index=np.random.randint(0,signal.shape[0]-config.step)
    sample = signal[rand_index:(rand_index + config.step)]
    X_sample=mfcc(sample,rate,nfilt=config.nfilt,numcep=config.nfeat,nfft=config.nfft)
    mn=min(np.amin(X_sample),mn)
    mx=max(np.amax(X_sample),mx)
    X.append(X_sample)
    y.append(instruments.index(label))
  config.min_=mn
  config.max_=mx
  X,y=np.array(X),np.array(y)
  X=(X-mn)/(mx-mn)
  if config.mode == 'conv':
    X=X.reshape(X.shape[0],X.shape[1],X.shape[2],1)
  elif config.mode == 'time':
    X=X.reshape(X.shape[0],X.shape[1],X.shape[2])
  y=to_categorical(y,num_classes=10)
  return X,y

"""## **Create Deep learning model**"""

def get_conv_model():
  model = Sequential()
  model.add(Conv2D(16,(3,3),activation='relu',strides=(1,1),padding='same',input_shape=input_shape))
  model.add(Conv2D(32,(3,3),activation='relu',strides=(1,1),padding='same'))
  model.add(Conv2D(64,(3,3),activation='relu',strides=(1,1),padding='same'))
  model.add(Conv2D(128,(3,3),activation='relu',strides=(1,1),padding='same'))
  model.add(MaxPool2D(pool_size=(2,2)))
  model.add(Dropout(0.5))
  model.add(Flatten())
  model.add(Dense(128,activation='relu'))
  model.add(Dense(64,activation='relu'))
  model.add(Dense(10,activation='softmax'))
  model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])
  model.summary()
  return model

def get_reccurent_model():
  model=Sequential()
  model.add(LSTM(128,return_sequences=True,input_shape=input_shape))
  model.add(LSTM(128,return_sequences=True))
  model.add(Dropout(0.5))
  model.add(TimeDistributed(Dense(64,activation='relu')))
  model.add(TimeDistributed(Dense(32,activation='relu')))
  model.add(TimeDistributed(Dense(16,activation='relu')))
  model.add(TimeDistributed(Dense(8,activation='relu')))
  model.add(Flatten())
  model.add(Dense(10,activation='softmax'))
  model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])
  model.summary()
  return model

if config.mode=='conv':
  X,y = build_rand_feat()
  y_flat = np.argmax(y,axis=1)
  input_shape = (X.shape[1],X.shape[2],1)
  model = get_conv_model()

elif config.mode=='time':
  X,y = build_rand_feat()
  y_flat = np.argmax(y,axis=1)
  input_shape = (X.shape[1],X.shape[2])
  model = get_reccurent_model()

class_weight  = compute_class_weight('balanced',np.unique(y_flat),y_flat)

model.fit(X,y,validation_split=0.3,epochs=10,batch_size=32,shuffle=True,class_weight=class_weight)

"""## **Save the model**"""

#!pip install h5py
from keras.models import model_from_json

model_json = model.to_json()
with open("model.json", "w") as json_file:
    json_file.write(model_json)

model.save_weights("model.h5")

"""## **Load the model**"""

json_file = open('model.json', 'r')
loaded_model_json = json_file.read()
json_file.close()

loaded_model = model_from_json(loaded_model_json)
loaded_model.load_weights("model.h5")
 
loaded_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

"""# **Musical Instrument Prediction**"""

X_test=[]
y_test=[]
wav_file = 'e92bf0fa.wav'
signal,rate=librosa.load('/content/drive/My Drive/wavfiles/Acoustic_guitar/'+wav_file,sr=16000)
label=df.at[wav_file,'label']
rand_index=np.random.randint(0,signal.shape[0]-config.step)
sample = signal[rand_index:(rand_index + config.step)]
X_sample=mfcc(sample,rate,nfilt=config.nfilt,numcep=config.nfeat,nfft=config.nfft)
X_test.append(X_sample)
y_test.append(instruments.index(label))
X_test,y_test=np.array(X_test),np.array(y_test)
X_test=(X_test-config.min_)/(config.max_-config.min_)
if config.mode == 'conv':
  X_test=X_test.reshape(X_test.shape[0],X_test.shape[1],X_test.shape[2],1)
elif config.mode == 'time':
  X_test=X_test.reshape(X_test.shape[0],X_test.shape[1],X_test.shape[2])

y_test=to_categorical(y_test,num_classes=10)

y_pred=loaded_model.predict_classes(X_test)
y_pred=instruments[y_pred[0]]

print('Actual instruments:',label)
print('Predicted instruments:', y_pred)



